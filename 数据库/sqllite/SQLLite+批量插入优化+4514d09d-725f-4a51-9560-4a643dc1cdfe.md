23/12/08在处理测试bug时,遇到一个对3k条数据进行操作的失败的问题,由于每条数据都很长,导致SQL过长报错,无法插入.然后写了一个拆分的方法对集合进行拆分然后在批量插入.

---

```Java
/**
     * 将数据分割成指定长度的子列表
     *
     * @param data   待分割的数据列表
     * @param length 分割的长度
     * @return 分割后的子列表列表
     */
    private <T> List<List<T>> splitData(List<T> data, int length) {
        List<List<T>> result = new ArrayList<>();
        if (data == null || data.isEmpty() || length <= 0) {
            // 返回默认值
            return result;
        }
        int size = data.size();
        int chunks = size / length;
        // 计算集合大小避免扩容
        int resultSize = chunks + (size % length > 0 ? 1 : 0);
        result = new ArrayList<>(resultSize);
        // 添加分组数据
        for (int i = 0; i < chunks; i++) {
            int start = i * length;
            int end = (i + 1) * length;
            result.add(data.subList(start, Math.min(end, size)));
        }
        // 添加剩余数据分组
        if (size % length > 0) {
            int start = chunks * length;
            int end = size;
            result.add(data.subList(start, end));
        }
        return result;
    }
```

```Java
   if (!CollectionUtils.isEmpty(applyDataList)) {
                    // 添加鉴定数据
                    List<List<AdApplyDataPO>> splitApplyDataList = splitData(applyDataList, 100);
                    for (List<AdApplyDataPO> applyData : splitApplyDataList) {
                        adApplyDataMapper.bathSaveIdentifyEntity(applyData);
                    }
                }
```

原本想着到这里就轻松结束了,结果请求超时!! 3k条数据没有加入进去回滚了!!
我这种小垃圾只能csdn,毕竟咱也不知道咋整啊,开搜,立刻搜~

> 咱这在广大网友的帮助下不久找到了吗,虽然找了很久

[How to insert multiple rows in SQLite?](https://stackoverflow.com/questions/1609637/how-to-insert-multiple-rows-in-sqlite/1734067#1734067)






```SQL
INSERT INTO ‘tablename’ (‘column1’, ‘column2’) VALUES
(‘data1’, ‘data2’),
(‘data1’, ‘data2’),
(‘data1’, ‘data2’),
(‘data1’, ‘data2’);
```



```SQL
INSERT INTO ‘tablename’
SELECT ‘data1’ AS ‘column1’, ‘data2’ AS ‘column2’
UNION SELECT ‘data3’, ‘data4’
UNION SELECT ‘data5’, ‘data6’
UNION SELECT ‘data7’, ‘data8’
```

![image.png](https://wang-rich.oss-cn-hangzhou.aliyuncs.com/md/image.png)

写mapper测试

---

```XML
    <insert id="bathSaveIdentifyEntity" parameterType="com.pde.p5.ad.po.AdApplyDataPO">
        INSERT INTO pdes_ad_apply_data
        <!-- 使用动态 SQL 进行循环插入 -->
        <if test="identifyDataList != null and identifyDataList.size() > 0">
            <foreach collection="identifyDataList" item="identifyData" separator="UNION">
                SELECT #{identifyData.apply_data_id} AS apply_data_id,
                #{identifyData.apply_id} AS apply_id,
                #{identifyData.apply_type} AS apply_type,
                #{identifyData.table_id} AS table_id,
                #{identifyData.entity_id} AS entity_id,
                ...
            </foreach>
        </if>
    </insert>
```

我的天就是快3k条数据优化前30s多超时回滚,优化后4s不到.完成!



